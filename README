A WZ->lvll VBS resonance selection using neural networks/BDT.
There are two programs for each method:
First for Neural Networks:
      - config_OPT_NN.py
Contains all relevant parameters and a list of input variables as well as the list of samples used 
as background and as signal.

      - OPT_VBS_NN.py:
 Trained with signals and backgrounds, the NN are implemented using the Keras package. They need simple 
ntuples as inputs containing all the necessary variables like Mjj, Detajj etc. For now the training is 
performed on mc16d samples. The background is a combination of the SM WZ QCD and WZ EW processes and 
the signal are the combined GM H5 samples with masses ranging from 200 to 900 GeV.

This is a simple fully connected NN, the principal hyper parameters are the number of layers, number of 
neurons per layer, the learning rate and momentum. The input is split into a training and validation set 
(70%/30%). After each epoch the accuracy is measured on the validation set and only the best performance 
is saved. Each signal mass is assigned a label corresponding to the resonance mass. The background events 
have a randomnly assigned label, taken of the same probability distribution as the signals. This should 
allow an optimal performance for all resonance masses. All Hyperparameters can be specified (see help).

      - Apply_NN.py:
This applies the NN selection to a given dataset, for example mc16a datasets. It takes as input the best 
performing NN found with OPT_VBS.py and a provided dataset. It then creates new samples in the output 
directory OutputRoot which are identical to the input files as well as an added variable probSignal which 
is the output of the NN. These ntuples can then be used to select the optimal cut on the NN output.

And for BDTs:
      - OPT_VBS_BDT.py:
The BDTs are implemented with sklearn. The Hyper parameters are: base_estimator forming the bossted ensemble,
 the learning rate and the boosting algorithm.

      - Apply_BDT.py:
Similar to Apply_NN this program applies the BDT selection to a given dataset. The output variable is
added to the original ntuple and stored in a new root file.

      INSTALLATION INSTRUCTION:

The program need the following packages installed:

keras
theano
root_numpy
sklearn
pandas
matplotlib (for figures)

These can be easily installed with pip (https://pip.pypa.io/en/stable/installing/),
To download pip:
curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
And then to install it:
python get-pip.py --user

Then you can install keras (https://keras.io/) by:
pip install keras --user

You will also need to install Theano:
pip install Theano --user

Once you installed theano you need to change the keras configuration:
~/.keras/keras.json
change entry backend to use it with theano:
       "backend": "theano"

To install sklearn:
pip install -U scikit-learn --user

To install pandas (for handling the datasets with python):
pip install pandas --user

For the figures install matplotlib
pip install -U matplotlib --user
